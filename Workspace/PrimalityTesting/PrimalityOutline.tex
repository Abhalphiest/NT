%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % 
% % 	Introduction Draft
%%
% %	 Math 371: 		Number Theory, Spring 2016
% % 	Author(s): 		Margaret Dorsey
% % 	Last Updated: 	04 / 16 / 2016	(see gitlog.txt for revision history)
% % 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Title and author(s)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\documentclass{article}
\usepackage{graphicx}
\usepackage{amsthm} %theorem formatting
\usepackage{amsfonts} % fonts
\usepackage{amssymb}
\usepackage{amsmath}
\newenvironment{intro}
  {\renewcommand\abstractname{Introduction}\begin{abstract}}
  {\end{abstract}}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % There are a lot of commands for theorems, declarations, etc.
% %
% % Here are some common ones. 
%%		-Margaret
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
\newtheorem*{theorem}{Theorem}
%%\newtheorem{lemma}{Lemma}
%%\newtheorem{proposition}{Proposition}
%%\newtheorem{scolium}{Scolium}   %% Maybe common was an overstatement..
\newtheorem*{definition}{Definition}
%%\newenvironment{proof}{{\sc Proof:}}{~\hfill QED}
%%\newenvironment{AMS}{}{}
%%\newenvironment{keywords}{}{}
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\newpage


%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  \section{ sectionName }
%%	\subsection{ name}
%%	\subsubsection{name}
%%	etc..
%%  Use sectioning commands for headings. Often longer articles are divided into a few sections.
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%%  use /par to start a new paragraph, // for a simple line break.
%%
%%  You must use labelling commands, e.g. \label, \ref,
%%  \bibitem, and \cite to refer to sections of your document, such as
%%  see Section~\ref{sectionname}, see Figure~\ref{figurename}, or bibliography entries,
%%  such as see~\cite{citationname}.  Otherwise the look of the numbers, and sometimes the numbers
%%  themselves, will get messed up.
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{ Primality Testing }

\par First, we will treat the various methods of determining whether or not a number is prime, or attempting to show that a number is composite, which is generally a much more approachable problem. At first glance, it seems strange to have methods for primality testing that are distinct from factorization methods - after all, if you can obtain the prime factorization of a number, it is trivial to determine primality from that factorization. However, factorization methods are in general more computationally expensive and difficult than the methods we will examine in this section. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{ Primality Tests and Composite Tests }

\par Any viable algorithmic method for testing primality straightforwardly is essentially a condition on a number $n$ that, when met, necessitates that $n$ is prime. Thus if the condition is not met, $n$ is composite. Such tests are certainly extremely convenient to directly determine the primality of $n$, but unfortunately methods of this form are usually rather complex and usually restricted to $n$ either of a particular form or within some bounded range. We call these tests \textit{primality tests}.

\par In addition to primality tests, which never incorrectly indicate primality, we also have many tests that are comparatively simple and computationally efficent, which occasionally fail to identify primes as prime, but never indicate that a composite number is a prime. We will call these tests, which never incorrectly indicate compositeness \textit{compositeness tests}.

\par It is of the utmost importance to note before moving on that while the conditions of a primality or compositeness test being met guarantees that the number is either prime or composite respectively, and a failed primality test proves compositeness, a failed compositeness test does \textit{not} necessitate that the number is prime.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection*{ The Sieve of Eratosthenes }

\par Sieving, in general, is a process where a series of operations are applied to every number in a large, regularly spaced set of integers in order to find numbers with certain characteristics.

\par The Sieve of Eratosthenes is considered the first algorithmic method developed for factorization and primality testing. As such, it is admittedly very crude, but the theoretical basis of the method gives us some perspective on the properties and distribution of prime numbers, and of the fundamental ideas upon which further primality tests can be built. Because the Sieve of Eratosthenes is more generally suitable for algorithmic factorization of a number, we will treat it rather lightly here and revisit it in more detail when we examine factorization methods.

\par The applicability of Eratosthenes' sieve to primality testing stems from the idea of \textit{trial division}, where given an integer $n$, we attempt to divide $n$ by every integer that could possibly be a factor. If the number divides $n$, then it is a factor of $n$, and because possible factors must be bounded above by $n$ itself, we are guaranteed a finite number of computations. In fact, we need only test factors less than $\sqrt{n}$, recovering greater factors as the quotient of a successful division by a lesser factor. Additionally, after each successful division, only the quotient need be tested further, resulting in easier computation as more factors are found (although for our purposes we have no need to ever find more than one factor). None of these facts are particularly reassuring computationally, but they provide some background for the use of our sieve.

\par The sieve can be thought of as a list or array of $N - 1$ consecutive integers, beginning with $2$. We recognize that $2$ is prime, and thus every multiple of $2$ is composite. We then remove $4$,$6$, etc. from our list, and are left with $2$ and the odd integers. We then recognize $3$ as prime, because it is still in the list, and remove all multiples of $3$ in the same way. $5$ has not been removed from the list, and so it is prime. We then repeat our method. Continuing this way until the end of the set has been reached, we have constructed a set of all prime numbers up to $N$. It is intuitive that slight modifications to this process can provide the least prime factors, or even the entire factorization, of all numbers up to $N$ as well.

\par It is a fair observation that this is not a test that can be applied to a single number, but rather construction of a set that will prove a number $n$ prime if $n$ is an element of the set, and composite if $n < N$ and $n$ is not in the set. This is not ideal, but combined with our method of trial division, and given that $76\%$ of odd integers have a prime factor less than $100$ \citep{riesel}, precompiling a list of primes up to a certain bound and performing trial divisions of only those prime numbers on a given $n$ can prove many numbers composite without having to resort to more rigorous compositeness or primality tests.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection* {Fermat's Theorem and Resulting Compositeness Tests}

\par Among the many limitations of Eratosthenes' sieve is its lack of precision - it is impossible to simply prove a given number $n$ prime or composite, you must construct the entire set of primes up to $n$ in the worst case to say anything about $n$ at all. To remedy this problem, we move on to another elementary method that can test $n$ directly, a compositeness test based on a theorem of Fermat.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%	
\subsubsection*{Fermat's Theorem}

\newtheorem*{fermattheorem}{Fermat's Theorem}
\begin{fermattheorem}
If a positive integer $p$ is a prime and $(a,p) = 1$, then
	$$a^{p-1} \equiv 1 \pmod p$$
\end{fermattheorem}

\par Fermat's theorem cannot be used as a primality test, as we will examine further when we define pseudoprimes, but we can use the converse of the theorem to develop a test for compositeness.

\newtheorem*{fermatconverse}{Converse of Fermat's Theorem}
\begin{fermatconverse}
If $n$ and $a$ are positive integers such that $(a,n) = 1$ and
	$$a^{n-1} \not\equiv 1 \pmod n,$$
	then $n$ cannot be prime. Hence $n$ is composite.
\end{fermatconverse}

\par This simple compositeness test will prove very useful to us, given its theoretical and computational simplicity and the relative ease of multiplication
of integers modulo $n$. Of course, one of the foremost weaknesses of Fermat compositeness tests is immediately apparent - the need for an appropriate $a$. As we will see in the very next section, not every $a$ satisfying the conditions will prove a composite $n$ composite. For now, we will assume that we simply iterate through all $a$ relatively prime to $n$, searching for an $a$ that proves $n$ composite. This is, of course, not a bounded process, and so in practice we would establish an upper bound for $a$ which would result in an inconclusive test if reached before a suitable $a$ is found. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{ Pseudoprimes and Carmichael Numbers }
To expand upon our problem with the infinitude of possible $a$ values, there are composite numbers that will behave similarly to primes when Fermat's theorem is applied to them for certain $a$. We will call these composites \textit{Fermat pseudoprimes base $a$}.
\begin{definition}
A \textit{ Fermat pseudoprime} base $a$ is an odd composite number $m$ for which 
$$ a^{m-1} \equiv 1 \pmod m \text{ holds.}$$  
\end{definition}

 \par In general, a \textit{pseudoprime} is a composite number that behaves like a prime in the context of a compositeness test (we will see other pseudoprimes very soon.) Interestingly, if all Fermat pseudoprimes could be identified for a fixed base $a$, we could then use Fermat's Theorem with only base $a$ as a primality test. Unfortunately, this cannot be generally accomplished, but in computational applications this idea is exploited for fast primality testing of $n$ of a fixed length by classifying all Fermat pseudoprimes base $a$ up to some upper bound $N > n$, applying Fermat's test to $n$, and checking to see if it is among the pseudoprimes if it is not proven composite. This rather practical sidestep of the limitations of a compositeness test is extremely useful for comparatively small $n$.
 
 \par The existence of Fermat pseudoprimes prompts a question - can all Fermat pseudoprimes be proven composite eventually, given enough bases $a$ are tested? The answer, unfortunately, is no. There exist numbers that will be Fermat pseudoprimes base $a$ for all valid $a$, and these\textit{ Carmichael numbers} are explicitly defined as follows:
 
 \begin{definition}
  A composite number $n$ such that $a^{n -1} \equiv 1 \pmod n$ for all $a$ relatively prime to $n$ is called a \textit{Carmichael Number}.
 \end{definition}
 
 A Carmichael number, the smallest of which is $561$ \citep{riesel}, will never be revealed as composite by a Fermat's Theorem test. The existence of Carmichael numbers are a serious hindrance to the Fermat compositeness test, although we have some luck in they can be characterized further than their definition.

\begin{theorem} A positive integer $n$ is a Carmichael number if and only if $p-1$ divides $n-1$ for every prime factor of $n$, $n$ is composite, and $n$ is squarefree.
\end{theorem}

\begin{proof}
First, suppose that $n$ is a composite number that square free, and $p-1 \mid n-1$ for every prime factor $p$ of $n$, and that $a$ is an arbitrary integer relatively prime to $n$.
\par By hypothesis, $n$ is square free, so $n = p_1 p_2 p_3 \ldots p_k$, with $p_i$ all distinct primes. Because $a$ is relatively prime to $n$, $a$ is also relatively prime to $p_i$ for all $i \in {1, \ldots, k}$. Thus, $a^{p-1} \equiv 1 \pmod{p_i}$ for all such $i$ by Fermat's Theorem.
\par However, because $p -1 \mid n -1$, $a^{n-1} = (a^{p-1})^t \equiv (1)^t = 1 \pmod{p_i}$ for some $t \in \mathbb Z$. Because $p_i \mid a^{n-1} - 1$ for all $i$, and all $p_i$ are distinct primes, $n = p_1p_2p_3 \ldots p_k \mid a^{n-1} - 1$. Thus $a^{n-1} \equiv 1 \pmod n$ for any arbitrary $a$ relatively prime to $n$, and $n$ is a Carmichael number.
\par
We now suppose that a composite $n$ is a Carmichael number, so $a^{n-1} \equiv 1 \pmod n$ for all $a$ relatively prime to $n$. $n = p_1^{\alpha_1}\cdot \ldots p_k^{\alpha_k}$, and so $p_i^{\alpha_i} \mid a^{n-1} - 1 $ and $(a,p_i) = 1$ for all $i \in \{1, \ldots, k\}$. Let $r$ be an integer such that $n = p_i^{\alpha_i} r$. Obviously, $p_i^{\alpha_i}$ and $r$ are relatively prime, so by the Chinese Remainder Theorem we have a unique solution of the system
	$$x \equiv a_1 \pmod{p_i^{\alpha_i}}$$
	$$x \equiv 1 \pmod{r}$$
where $a_1$ is a primitive root of $p_i^{\alpha_i}$ (Recall from our brief introduction of primitive roots that $p_i^{\alpha_i}$ is guaranteed $\phi(\phi(p_i^{\alpha_i}))$ of these).
\par Suppose that $\alpha_i = 1$. $x$ is relatively prime to both $p_i$ and $r$, so we have $x \equiv a \pmod{p_i \cdot r = n}$, which gives us $x^{n-1} \equiv 1 \pmod n$ and $x^{n-1} \equiv 1 \pmod {p_i}$ as well. However, $x^{p_i - 1} \equiv 1 \pmod{p_i}$, and $p_i - 1$ is the least power of $x$ such that $x$ is equivalent to $1$ modulo $p_i$, and have $p_i -1 \mid n - 1$ for all $i$. 
\par Now suppose that $\alpha_i >1$ for some $i$, so that $n$ is not squarefree. $x^{n-1} \equiv 1 \pmod{p_i^{\alpha_i}}$, and by Euler's theorem, $x^{\phi(p_i^{\alpha_i})} = x^{p_i^{\alpha_i - 1}(p_i - 1))}  \equiv 1 \pmod{p_i^{\alpha_i}}$. Thus because $p_i^{\alpha_i -1}(p_i - 1)$ is the least power of $a_1$ equivalent to $1$ modulo $pi^{\alpha_i}$, $p_i^{\alpha_i -1}(p_i - 1) \mid n - 1$. However, $p_i^{\alpha_i - 1} \mid n - 1$ is a contradiction, because $(n, n-1) = 1$ and $p_i^{\alpha_i - 1} \mid n$. Thus $n$ must also be squarefree, and we are done. 
\end{proof}

\par Despite this nice result, it is very troubling to have composite numbers that we could not identify even with infinite computational time, and because there are infinitely many Carmichael numbers, they cannot even be completely identified and compensated for. (A rather formidable  proof of the infinitude of Carmichael  numbers can be found in \citep{carmichael}).


\subsubsection*{Improving the Fermat test with Euler's Criterion}

There is clear motivation to improve our method, if possible, to avoid the significant problem presented by the existence of Carmichael numbers. One tool that we have at our disposal is the \textit{Euler Criterion for Quadratic Residues}, which is is stated below and proven in the Background section on quadratic residues.

\newtheorem*{eulerconverse}{Euler's Criterion as a Compositeness Test}

\begin{eulercriterion}
If $p$ is an odd prime and $(a,p) = 1$, 
$$a^{\nicefrac{n-1}{2}} \equiv \pm 1 \pmod p$$
where the sign of $1$ is chosen to match the value of Legendre's symbol $\left(\dfrac{a}{p} \right)$.
\end{eulercriterion}


This criterion's logical converse, much like Fermat's theorem, gives us a test for compositeness.
\begin{eulerconverse}
If $n$ is odd, $(a,n) = 1$, and
	$$a^{\nicefrac{n-1}{2}} \not\equiv \pm 1 \pmod n$$
	then $n$ is a composite number.
\end{eulerconverse}

To strengthen this compositeness test, we use Jacobi's symbol over Legendre's symbol, remembering that Jacobi's symbol sometimes misidentifies quadratic non-residues as residues when $n$ is composite.

\begin{eulerconverse}
If $n$ is odd, $(a,n) = 1$, and
	$$a^{\nicefrac{n-1}{2}} \not\equiv \pm 1 \pmod n$$
	then $n$ is a composite number.
	
\par If $a^{\nicefrac{n-1}{2}} \equiv \pm 1 \pmod n$ and
	$$a^{\nicefrac{n-1}{2}} \not\equiv \left(\dfrac{a}{n}\right) \pmod n$$
	then $n$ is composite. \\
\par
 If $a^{\nicefrac{n-1}{2}} \equiv \left(\dfrac{a}{n}\right) \pmod n$ holds, the test is inconclusive.
\end{eulerconverse}

As the last line of our definition and our knowledge of Jacobi's symbol might suggest, this compositness test also has pseudoprimes. We will call these \textit{Euler pseudoprimes}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection*{Euler Pseudoprimes and Strong Pseudoprimes}
We define an Euler pseudoprime in an analogous way to our definition of a Fermat pseudoprime.
\begin{definition}
Let $n$ be an odd composite number such that
	 $$a^{\nicefrac{n-1}{2}} \not\equiv \left(\dfrac{a}{n}\right) \pmod n$$ 
for some $a$ relatively prime to $n$.  Then $n$ is an \textit{Euler pseudoprime} base $a$.
\end{definition}

\par Unfortunately, there are some numbers that are both Carmichael numbers and Euler pseudoprimes. An example of one such number is $1729$.
\par Despite this disappointing fact,  many Carmichael numbers are revealed as composite by Euler's Criterion, and additionally, there is no analogue for Carmichael numbers in Euler pseudoprimes. If enough bases $a$ are tested, we will eventually prove the compositeness of any composite number.

\par To close this section, we present a final type of pseudoprime, which, like Euler pseudoprimes, can always be eventually proven composite by some base $a$.
\begin{definition}
An odd composite number $n$ with $n-1 = d\cdot2^s$, $d$ odd, is called a \textit{strong pseudoprime} for base $a$ if either
$a^d \equiv 1 \pmod n$ or $a^{d \cdot 2r} \equiv -1 \pmod n$, for some $r \in \{0, 1, \ldots, s-1\}$. 
\end{definition}

\par This test for pseudoprimes is intended, much like Euler pseudoprimes, to eliminate the problem of Carmichael numbers in the Fermat Compositeness test. Indeed, any Fermat pseudoprime will be eventually proven composite by the strong pseudoprime test if enough bases $a$ are tested.

\par The motivation (which is not a proof) for the test is as follows:
\\Any Fermat pseudoprime $n$ to base $a$ will satisfy the equivalence
	$$a^{n-1} - 1 \equiv 0 \pmod n$$
Because we assume that $n$ is odd if it is being tested for primality, $n = 2m+1$ for some integer $m$ and we have
	$$a^{2m} - 1 = (a^m - 1)(a^m+1) \equiv 0 \pmod{n}$$
If $n$ is a prime, it must divide one of these factors, but it cannot divide both because then it would need to divide all linear
combinations of them, including $(a^m - 1) - (a^m + 1) = -2$. Therefore we have 
	$$a^m \equiv \pm 1 \pmod n$$
We can write $n$ as $2^\alpha k + 1$, where $k$ is odd, and have 
	$$a^{n-1} - 1 = (a^k - 1)(a^k + 1)(a^{2k} + 1) \ldots (a^{2^{\alpha - 1} k} +1)$$
	
\par If $n$ divides exactly one of these factors but is composite, then it is a strong pseudoprime. Interestingly, if a number is
a strong pseudoprime to the base $a$, it will also be a Euler pseudoprime to $a$.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\subsection*{Elementary Primality Tests}

\par In the previous section, all the tests we examined could only possibly prove compositeness - because we are unable to test infinitely many bases in an Euler or Strong Pseudoprime test, there is no way for us to computationally prove that a number is prime using these methods, only to say that it is somewhat likely to be prime, or say with certainty that it is composite. 
\par In this section, we examine some methods of proving primality. These primality tests are much more complicated computationally and theoretically than compositeness tests, and unfortunately usually depend on factorization of a number, which is a slow and laborious process when performed, and very limiting to the form of $n$ when avoided. However, they are theoretically motivating, despite not being as practically useful as more modern primality tests.

\subsubsection*{Lehmer's Theorem}

\par The first method of actually proving primality that we will look at is based on a theorem by Lucas, proven by Lehmer.

\newtheorem*{lehmer}{Lehmer's Theorem}
\begin{lehmer}
Suppose $n-1 = \prod^n_{j=1} q_j^{\beta_j}$, with all $q_j$ distinct primes. If an integer $a$ exists such that 
	$$a^{\nicefrac{n-1}{q_j}} \neq 1 \pmod n \text{ for all } j = 1, \ldots, n$$
	$$\text { and such that }$$
	$$a^{n-1} \equiv 1\pmod n \text{, }$$
then $n$ is a prime number.
\end{lehmer}
We note that this theorem is an extension of Fermat's theorem. 
\begin{proof}
Consider $a^k \equiv 1 \pmod n$. The smallest such $k$ divides all possible $k$, including $n-1$. However, every divisor $k$ not equal to $n-1$ of $n-1$ divides at least one $\frac{n-1}{q_j}$. Thus if $k$ is  less than $n-1$,  $a^{\nicefrac{n-1}{q_j}} \equiv a^{tk}\equiv 1 \pmod n$ will hold for some $q_j$. This contradicts the assumptions of the theorem, and so $k = n-1$. However, by Euler's theorem, we know that $a^{\phi(n)} \equiv 1 \pmod n$ for all $a$ relatively prime to $n$, and that $\phi(n) < n-1$ for all composite numbers. If $\phi(n) < k$, it contradicts the assumption that $k$ is the smallest power of $a$ equivalent to $1$, and thus $\phi(n) = k = n-1$, and $n$ must be prime.
\end{proof}

\par From our knowledge of primitive roots, we know that any primitive root will be a suitable $a$ for Lehmer's Theorem. The problem inherent in this is that there is not an efficient, deterministic method to find primitive roots, or even quadratic non-residues. If $n$ is prime, then we will have $\phi(\phi(n)) = \phi(n-1) = (n-1) \prod (1- \frac{1}{q_j})$ primitive roots, but as the equation shows, if $n-1$ has many prime factors, especially many smal primel factors, primitive roots become a smaller proportion of possible $a$ values.

 \par Fortunately, Selfridge provides us with a relaxed version of Lehmer's theorem such that we do not need a primitive root to prove $n$ prime.
\begin{theorem}
Suppose $n-1 = \prod^n_{j=1} q_j^{\beta_j}$, with $q_j$ all distinct primes.  If for every $q_j$, there is an $a_j$ such that
	$$a_j^{\nicefrac{n-1}{q_j}} \not\equiv 1 \pmod n$$ 
	$$\textnormal{ while }$$
	$$a_j^{n-1} \equiv 1 \pmod n \text{, }$$
then $n$ is a prime.
\end{theorem}
The proof of this statement can be found in \citep{selfridge}.
\par This allows us to perform tests with multiple bases, and prove primality usually much more quickly than Lehmer's theorem applied directly, especially for primes where the least primitive root is large.
\par However, there is still a major stumbling block in practical applications of Lehmer's Theorem - the need to factorize $n -1$. Luckily, it is possible to relax the conditions of Lehmer's theorem in a way that allows us to test with only a partial factorization.

\begin{theorem}
Let $n - 1 = r \cdot f$, where $f$ is the factorized part of $n-1$ and $r$ is the unfactorized or remaining part such that $(r,f) = 1$, $r < f$, and $f = \prod^n_{j=1} q_j^{\beta_j}$, with all $q_j$ distinct primes.
\par If an integer $a$ exists such that
	$$\textnormal{gcd}(a^{\nicefrac{n-1}{q_j}} - 1, N) = 1 \text{ for all } j \text{, }$$
	$$\textnormal{ and }$$
	$$a^{n-1} \equiv 1 \pmod n \text{, }$$
then $n$ is a prime number.
\end{theorem}

There is an analogous theorem used in factorization, the Lehmer-Pocklington Theorem, developed from this theorem and a result called Pocklington's theorem.

\newtheorem*{pocklington}{Pocklington's Theorem}
\begin{pocklington}
Let $n - 1 = rq^n$, where $q$ is prime and $q \nmid r$. If there exists an integer $a$ satisfying
	$$\textnormal{gcd}(a^{\nicefrac{n-1}{q}} - 1, n) = 1 \textnormal{ such that } a^{n-1} \equiv 1 \pmod n \text{, }$$
then each prime factor $p$ of $n$ has the form $p = q^nm +1$.
\end{pocklington}

\par Pocklington's theorem was developed for factorization methods - and as such is a bit of a detour from our primality tests - but in certain cases it can be used to prove, for instance, that all prime factors of $n$ are greater than $\sqrt{n}$, thus proving $n$ prime. In fact, we will see Pocklington's theorem again in the Elliptic Curve primality test.


\subsubsection*{P\'{e}pin's and Proth's Theorems}
Another possible sidestep of the need to factor $n-1$ is available when $n$ happens to be a Fermat number, or a number of the form $2^{2^r} + 1$ (These happen to be the only sums of a power of 2 and 1 that can be prime). In this case, $n - 1$ has the minimum possible number of distinct prime factors, and thus is very suited to a Lehmer's Theorem test. In fact, for a Fermat number $n$, the requirements of Lehmer's Theorem become
	$$a^{\nicefrac{n - 1}{2}} = a^{2^{2^{r-1}}} \not\equiv 1 \pmod n $$
	$$\text{ and } $$
	$$a^{n - 1} = a^{2^{2^{r}}} \equiv 1 \pmod n \text{, }$$
which essentially reduces to 
	$$x^2 \equiv 1 \pmod n$$
	$$\text{ and }$$
	$$x \not \equiv 1 \pmod n$$
where $x = a^{2^{2^{r-1}}}$.

If $n$ is prime, then $x^2 \equiv 1 \pmod n$ will have exactly two solutions, namely $x \equiv \pm 1 \pmod n$. $x \equiv 1 \pmod n$ violates the conditions of Lehmer's theorem, and so $x \equiv -1 \pmod n$ when $n$ is prime. This motivates a need for an $a$ such that 
	$$x \equiv a^{\nicefrac{n - 1}{2}} \equiv -1 \pmod n$$
	
\par Noting that Euler's Criterion gives us that $a$ must be a quadratic non-residue of $n$, along with the fact (that we will state without proof) that $3$ is a quadratic non-residue of all primes of the form $12n \pm 5$ and the observation that $2^{2^k} \equiv 4 \pmod {12}$ for all $k$ inspires (but does not prove) P\'{e}pin's Theorem, which is stated below.

\newtheorem*{pepin}{P\'{e}pin's Theorem}
\begin{pepin}
A Fermat number $n = 2^{2^r} + 1$, $n \geq 1$ is prime if and only if 
	$$ a^{\nicefrac{n - 1}{2}} \equiv  - 1 \pmod n$$
\end{pepin}

It is worth mentioning that the binary computer makes the division by $n$ necessary to reduce powers of $a$ modulo $n$ very computationally simple, due to $n$ being a power of $2$ plus $1$ and therefore very simply expressed in binary. This makes P\'{e}pin's test a very attractive test for Fermat number primes. 

With both  P\'{e}pin's Theorem and relaxed version of Lehmer's theorem, we obtain Proth's Theorem, stated below.

\newtheorem*{proth}{Proth's Theorem}
\begin{proth}
Suppose $n$ is of the form $n = m \cdot 2^k + 1$, with $2^k > m$ and $m$ odd. If there exists an integer $a$ such that 
	$$a^{\nicefrac{n-1}{2}} \equiv -1 \pmod n \text{, }$$
then $n$ is prime.
\end{proth}
A proof of both P\'{e}pin's and Proth's theorems can be found in \citep{yale}. \\
\par There is yet another way to ease the difficulty of factoring $n - 1$. By using a different compositeness test than Fermat's theorem that allows us to attempt to factorize a number other than $n - 1$, we may end up with a number that proves easier to factor. For example, primality tests based on Lucas Sequences give an analogue to Lehmer's theorem in quadratic fields, where $N+1$ may be factored instead of $N-1$. The theory of quadratic fields is beyond the scope of this paper, and so we do not address Lucasian or similar methods, but their existence is worth noting and can be investigated further in \citep{riesel} and \citep{yale}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection*{Modern Primality Tests}

%% We will treat these very lightly 
\par Of the primality tests covered in the previous section, none are of practical use for all numbers. Computationally viable methods such as P\'{e}pin's Theorem only apply to primes of a certain form, and the need for factorization, even partial factorization, and identification of primitive roots cripples Lehmer's Theorem computationally. Fortunately, there exist more suitable methods used today in primality testing. 
\par These tests are, in general, quite theoretically and algorithmically complicated, and so we give only a brief introduction to the ideas behind modern primality tests and do not attempt to rigorously present them.

\subsubsection*{The Jacobi Sum Primality Test}

\par The foundation of the Jacobi Sum Primality test is the strong pseudoprime test we have seen and its use of cyclotomic number fields. Put in the simplest terms possible, the test uses information from a combination of compositeness tests based the strong pseudoprime test in cyclotomic rings. The results of these tests is then used to construct a sieve for the possible prime divisors of a number $n$ until in the end it is proven to be its own sole prime divisor, or a prime number, or a prime divisor is found that proves $n$ composite.

 \par Also called the Adleman-Pomerance-Rumely primality test,  the Jacobi Sum Primality test does not rely on randomness  like many of the more efficient primality tests, allowing it to be a deterministic primality test in exchange for computational superiority. Interestingly enough, our strong pseudoprime test may also form a deterministic primality test, if the Extended Riemann Hypothesis is assumed to be true. It was this near miss that prompted its adaptation into what is now the Jacobi Sum test, which thankfully does not rely upon unproven results.

\subsubsection*{Elliptic Curve Primality Testing}

Elliptic curve primality testing is based on the use of the properties of the group of points modulo $n$ on an elliptic curve. Unlike the Jacobi Sum Test, Elliptic Curve testing is probablilistic, and therefore may theoretically fail. That isn't to say that it gives the wrong answer - that would make it not a primality test - but it is possible for the algorithm to run indefinitely, never proving even a prime $n$ prime.  Despite this, elliptic curve methods are among the fastest and most popular primality testing algorithms used today.
\par Stated very generally, elliptic curve methods use elliptic curves generated either by random integers $a$ and $b$ in the case of the Goldwasser-Killian algorithm or by methods guaranteed to generate curves that will be computationally simpler for the Atkin-Morain test. We then consider the equation $y^2 = x^3 + ax + b$ modulo $n$. If $n$ is prime (and we may practically assume that it is, given that any $n$ subjected to an Elliptic Curve test is likely to have passed all of the less expensive compositeness tests available), then the set of all integer solutions of this curve will have certain properties, which we will hope to verify and thus prove the primality of $n$.
\par The rest of the test depends on the fact that the only non-invertible equivalence class modulo a prime is $0$, or the class containing multiples of the prime itself. The computations necessary for proving a number $n$ prime using an elliptic curve cannot be performed on a non-invertible element modulo $n$,  but if we end up encountering such an element outside of the multiples of $n$, we have shown that $n$ cannot be prime and the test can conclude. 
\par The integer points of our elliptic curve $E$ are then manipulated and tested with an analogue of our earlier theorem by Pocklington. These tests will either prove $n$ composite by finding a prime factor not equal to $n$, or allow us to prove $n$ prime given that we can verify the primality of a computed probable prime factor of $n$ $q$, because we will have chosen $q > \sqrt{n}$. Of course, the method can then be recursively applied to $q$, each time resulting in a smaller probable prime (and of course applying less computationally taxing compositeness tests to each new probable prime before returning to elliptic curves). With this recursion, we will either end up proving the compositeness of one and therefore all of our probable primes, or arriving at a well known prime and proving them all prime. 
\par A more explicit and instructive treatment of elliptic curve methods can be found in \citep{koblitz}.





%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}
